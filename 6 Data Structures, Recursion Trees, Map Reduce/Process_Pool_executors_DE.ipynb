{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89f6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job_postings = pd.read_csv('DataEngineer.csv')\n",
    "num_rows = job_postings.shape[0]\n",
    "num_cols = job_postings.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bcfc0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Engineer (Healthcare Domain experi...</td>\n",
       "      <td>$80K-$150K (Glassdoor est.)</td>\n",
       "      <td>Key Responsibilities\\n\\n- Architect, build, an...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Enterprise Integration\\n3.4</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>1998</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$25 to $50 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "1  Senior Data Engineer (Healthcare Domain experi...   \n",
       "\n",
       "               Salary Estimate  \\\n",
       "1  $80K-$150K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "1  Key Responsibilities\\n\\n- Architect, build, an...     3.4   \n",
       "\n",
       "                  Company Name      Location      Headquarters  \\\n",
       "1  Enterprise Integration\\n3.4  New York, NY  Jacksonville, FL   \n",
       "\n",
       "                  Size  Founded  Type of ownership     Industry  \\\n",
       "1  51 to 200 employees     1998  Company - Private  IT Services   \n",
       "\n",
       "                   Sector                   Revenue Competitors Easy Apply  \n",
       "1  Information Technology  $25 to $50 million (USD)          -1         -1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_postings[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e447353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2528, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_postings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd769f",
   "metadata": {},
   "source": [
    "### The job_postings DataFrame from the previous screen is still available.\n",
    "\n",
    "1. Use the DataFrame.str.lower() method to make the Job Description column lowercase. Assign it back to job_postings[\"Job Description\"].\n",
    "\n",
    "2. Initialize an empty dictionary called frequency.\n",
    "\n",
    "3. Use the Series.str.count() and Series.sum() methods to calculate the frequency of the string \"postgres\" on the Job Description column of the job_postings DataFrame. Assign it to frequency[\"postgres\"].\n",
    "\n",
    "4. In the same way, calculate the frequency of the string \"sql\" on the Job Description column of the job_postings DataFrame. Assign it to frequency[\"sql\"].\n",
    "\n",
    "5. Print the value of frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7c0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'postgres': 293, 'sql': 3313, 'python': 2058}\n"
     ]
    }
   ],
   "source": [
    "job_postings[\"Job Description\"] = job_postings[\"Job Description\"].str.lower()\n",
    "\n",
    "frequency = {}\n",
    "\n",
    "frequency[\"postgres\"] = job_postings[\"Job Description\"].str.count(\"postgres\").sum()\n",
    "\n",
    "frequency[\"sql\"] = job_postings[\"Job Description\"].str.count(\"sql\").sum()\n",
    "frequency[\"python\"] = job_postings[\"Job Description\"].str.count(\"python\").sum()\n",
    "\n",
    "\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2f8fa",
   "metadata": {},
   "source": [
    "### The job_postings DataFrame from the previous screen is still available and the Job Description column is in lowercase.\n",
    "\n",
    "1. Use the pandas.read_csv() function to read the Skills.csv file. Assign it to a variable named skills.\n",
    "\n",
    "2. Initialize an empty dictionary called frequency.\n",
    "\n",
    "3. Use a for loop to iterate over all skill names in skills[\"Name\"] with a variable named skill_name.\n",
    "\n",
    "4. Inside the for loop, calculate the number of occurrences of skill_name in the Job Description column of the job_postings DataFrame. Assign the result to frequency[skill_name].\n",
    "\n",
    "5. Outside of the for loop, use the frequency dictionary to print the frequency of \"programming\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dbdc8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ide': 8714,\n",
       " 'sql': 3313,\n",
       " 'osi': 2673,\n",
       " 'cli': 2270,\n",
       " 'python': 2058,\n",
       " 'aws': 1812,\n",
       " 'security': 1772,\n",
       " 'java': 1522,\n",
       " 'scala': 1515,\n",
       " 'spark': 1505,\n",
       " 'network': 1451,\n",
       " 'excel': 1233,\n",
       " 'oop': 1180,\n",
       " 'rest': 1176,\n",
       " 'programming': 1139,\n",
       " 'data pipeline': 1117,\n",
       " 'etl': 1102,\n",
       " 'git': 1098,\n",
       " 'functional': 1049,\n",
       " 'hadoop': 997,\n",
       " 'azure': 925,\n",
       " 'server': 891,\n",
       " 'software engineer': 891,\n",
       " 'agile': 886,\n",
       " 'san': 871,\n",
       " 'machine learning': 831,\n",
       " 'data warehouse': 729,\n",
       " 'kafka': 598,\n",
       " 'scripting': 594,\n",
       " 'hive': 580,\n",
       " 'algorithm': 536,\n",
       " 'linux': 529,\n",
       " 'nosql': 484,\n",
       " 'business intelligence': 431,\n",
       " 'tableau': 377,\n",
       " 'devops': 370,\n",
       " 'redshift': 344,\n",
       " 'docker': 327,\n",
       " 'shell': 326,\n",
       " 'javascript': 318,\n",
       " 'oracle': 316,\n",
       " 'sql server': 310,\n",
       " 'snowflake': 306,\n",
       " 'postgres': 293,\n",
       " 's3': 292,\n",
       " 'kubernetes': 287,\n",
       " 'data structures': 284,\n",
       " 'sas': 278,\n",
       " 'airflow': 274,\n",
       " 'data lake': 274,\n",
       " 'scrum': 256,\n",
       " 'google cloud': 253,\n",
       " 'statistics': 246,\n",
       " 'mathematics': 213,\n",
       " 'jenkins': 204,\n",
       " 'data visualization': 203,\n",
       " 'data architecture': 203,\n",
       " 'project management': 201,\n",
       " 'cassandra': 194,\n",
       " 'hbase': 182,\n",
       " 'react': 180,\n",
       " 'backend': 170,\n",
       " 'mongodb': 162,\n",
       " 'sap': 158,\n",
       " 'html': 154,\n",
       " 'elasticsearch': 136,\n",
       " 'storm': 134,\n",
       " 'mapreduce': 130,\n",
       " 'json': 129,\n",
       " 'bash': 129,\n",
       " 'angular': 128,\n",
       " 'ruby': 125,\n",
       " 'hdfs': 124,\n",
       " 'vertica': 122,\n",
       " 'pig': 116,\n",
       " 'deep learning': 115,\n",
       " 'css': 112,\n",
       " 'microservices': 109,\n",
       " 'ssl': 107,\n",
       " 'presto': 95,\n",
       " 'impala': 92,\n",
       " 'powershell': 90,\n",
       " 'redis': 89,\n",
       " 'soa': 86,\n",
       " 'maven': 85,\n",
       " 'phoenix': 81,\n",
       " 'iam': 80,\n",
       " 'mpp': 66,\n",
       " 'azure data factory': 63,\n",
       " 'computer vision': 62,\n",
       " 'concur': 61,\n",
       " 'pandas': 58,\n",
       " 'flink': 54,\n",
       " 'encryption': 49,\n",
       " 'frontend': 48,\n",
       " 'sqoop': 45,\n",
       " 'luigi': 44,\n",
       " 'scikit': 42,\n",
       " 'tomcat': 42,\n",
       " 'numpy': 41,\n",
       " 'selenium': 41,\n",
       " 'jupyter': 40,\n",
       " 'map reduce': 38,\n",
       " 'powerbi': 36,\n",
       " 'flume': 35,\n",
       " 'neural network': 34,\n",
       " 'yarn': 33,\n",
       " 'web development': 33,\n",
       " 'oozie': 32,\n",
       " 'django': 31,\n",
       " 'ssas': 29,\n",
       " 'zookeeper': 26,\n",
       " 'eclipse': 25,\n",
       " 'oauth': 20,\n",
       " 'nodejs': 19,\n",
       " 'solr': 19,\n",
       " 'greenplum': 18,\n",
       " 'probability': 17,\n",
       " 'data wrangling': 16,\n",
       " 'scipy': 16,\n",
       " 'cron': 16,\n",
       " 'data cleaning': 15,\n",
       " 'jwt': 15,\n",
       " 'jdbc': 14,\n",
       " 'apache nifi': 13,\n",
       " 'gdpr': 13,\n",
       " 'web scraping': 13,\n",
       " 'drill': 12,\n",
       " 'apache beam': 11,\n",
       " 'microsoft power bi': 11,\n",
       " 'quicksight': 11,\n",
       " 'mllib': 11,\n",
       " 'time series': 10,\n",
       " 'sandbox': 10,\n",
       " 'ssh': 10,\n",
       " 'sparksql': 9,\n",
       " 'kerberos': 7,\n",
       " 'circleci': 7,\n",
       " 'calculus': 7,\n",
       " 'lucene': 6,\n",
       " 'algebra': 5,\n",
       " 'sqlite': 5,\n",
       " 'arrow': 5,\n",
       " 'oracle sql': 3,\n",
       " 'kudu': 3,\n",
       " 'ambari': 3,\n",
       " 'pattern recognition': 3,\n",
       " 'jetty': 3,\n",
       " 'mahout': 2,\n",
       " 'apache crunch': 2,\n",
       " 'hue': 2,\n",
       " 'wms': 2,\n",
       " 'anaconda': 2,\n",
       " 'transact-sql': 1,\n",
       " 'knime': 1,\n",
       " 'haskell': 1,\n",
       " 'identity access management': 1,\n",
       " 'rapidminer': 0,\n",
       " 'tensor flow': 0,\n",
       " 'heron': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv('Skills.csv')\n",
    "\n",
    "frequency = {}\n",
    "\n",
    "for skill_name in skills[\"Name\"]:    \n",
    "    frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "\n",
    "dict(sorted(frequency.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c413255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def count_skills(job_postings, skills):\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"]:\n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "start = time.time()\n",
    "count_skills(job_postings, skills)\n",
    "end = time.time()\n",
    "\n",
    "runtime = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9b5e9",
   "metadata": {},
   "source": [
    "### The job_postings and skills DataFrames are still available.\n",
    "\n",
    "1. Declare a function make_chunks() with two arguments:\n",
    "    * df: the DataFrame to split\n",
    "    * num_chunks: the number of chunks we want\n",
    "\n",
    "2. Implement the make_chunks() function by doing the following:\n",
    "    1. Assign the number of rows in the DataFrame to a variable named num_rows. Recall that the number of rows in a DataFrame is the first component of the DataFrame.shape attribute.\n",
    "    2. Calculate the chunk_size by using the math.ceil() function to round up the result of dividing num_rows by num_chunks.\n",
    "    3. Use the list comprehension from the learn section to calculate the chunks. Return the result.\n",
    "\n",
    "3. Test your function by breaking the skills DataFrame into 8 chunks. Assign the result to skill_chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da04d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                     Name\n",
      "0                  python\n",
      "1                     sql\n",
      "2             programming\n",
      "3                   spark\n",
      "4                     aws\n",
      "5                    java\n",
      "6                  hadoop\n",
      "7                     etl\n",
      "8        machine learning\n",
      "9                   scala\n",
      "10                  agile\n",
      "11  business intelligence\n",
      "12                  kafka\n",
      "13                  azure\n",
      "14                  nosql\n",
      "15                  linux\n",
      "16                   hive\n",
      "17              algorithm\n",
      "18         data warehouse\n",
      "19             functional,              Name\n",
      "20      scripting\n",
      "21     statistics\n",
      "22       security\n",
      "23        network\n",
      "24            git\n",
      "25         server\n",
      "26       redshift\n",
      "27       postgres\n",
      "28         devops\n",
      "29        airflow\n",
      "30        tableau\n",
      "31         docker\n",
      "32     javascript\n",
      "33  data pipeline\n",
      "34    mathematics\n",
      "35         oracle\n",
      "36     sql server\n",
      "37             s3\n",
      "38   google cloud\n",
      "39        mongodb,                   Name\n",
      "40           data lake\n",
      "41     data structures\n",
      "42           cassandra\n",
      "43               hbase\n",
      "44       elasticsearch\n",
      "45                rest\n",
      "46          kubernetes\n",
      "47               scrum\n",
      "48               shell\n",
      "49       deep learning\n",
      "50  project management\n",
      "51  data visualization\n",
      "52             jenkins\n",
      "53                hdfs\n",
      "54   data architecture\n",
      "55               excel\n",
      "56           mapreduce\n",
      "57              impala\n",
      "58           snowflake\n",
      "59                ruby,                  Name\n",
      "60              flink\n",
      "61  software engineer\n",
      "62            backend\n",
      "63              storm\n",
      "64                sas\n",
      "65             pandas\n",
      "66                pig\n",
      "67               json\n",
      "68               bash\n",
      "69                sap\n",
      "70              luigi\n",
      "71              oozie\n",
      "72            powerbi\n",
      "73       transact-sql\n",
      "74        apache nifi\n",
      "75             presto\n",
      "76            jupyter\n",
      "77             scikit\n",
      "78              numpy\n",
      "79              redis,                   Name\n",
      "80       microservices\n",
      "81               maven\n",
      "82  azure data factory\n",
      "83               sqoop\n",
      "84               flume\n",
      "85               react\n",
      "86     computer vision\n",
      "87         apache beam\n",
      "88                 oop\n",
      "89                yarn\n",
      "90          powershell\n",
      "91                html\n",
      "92                 cli\n",
      "93                 css\n",
      "94              nodejs\n",
      "95          oracle sql\n",
      "96                ssas\n",
      "97       data cleaning\n",
      "98             angular\n",
      "99                gdpr,                    Name\n",
      "100                 san\n",
      "101            frontend\n",
      "102         time series\n",
      "103              django\n",
      "104      data wrangling\n",
      "105     web development\n",
      "106             vertica\n",
      "107                 mpp\n",
      "108                solr\n",
      "109          map reduce\n",
      "110            kerberos\n",
      "111        web scraping\n",
      "112          encryption\n",
      "113                 ssl\n",
      "114            selenium\n",
      "115              mahout\n",
      "116         probability\n",
      "117      neural network\n",
      "118               scipy\n",
      "119  microsoft power bi,               Name\n",
      "120     quicksight\n",
      "121            iam\n",
      "122          mllib\n",
      "123       sparksql\n",
      "124           kudu\n",
      "125      zookeeper\n",
      "126  apache crunch\n",
      "127        eclipse\n",
      "128          oauth\n",
      "129         tomcat\n",
      "130            soa\n",
      "131            hue\n",
      "132            ide\n",
      "133       circleci\n",
      "134     rapidminer\n",
      "135            wms\n",
      "136          knime\n",
      "137    tensor flow\n",
      "138         concur\n",
      "139           cron,                            Name\n",
      "140                        jdbc\n",
      "141                   greenplum\n",
      "142                     algebra\n",
      "143                     sandbox\n",
      "144                         ssh\n",
      "145                    calculus\n",
      "146                      ambari\n",
      "147                     haskell\n",
      "148                    anaconda\n",
      "149                         osi\n",
      "150         pattern recognition\n",
      "151                       drill\n",
      "152                         jwt\n",
      "153  identity access management\n",
      "154                     phoenix\n",
      "155                      lucene\n",
      "156                       jetty\n",
      "157                      sqlite\n",
      "158                       arrow\n",
      "159                       heron]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def make_chunks(df, num_chunks):\n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows / num_chunks)\n",
    "    chunks = [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "skill_chunks = make_chunks(skills, 8)\n",
    "print(skill_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2961c29",
   "metadata": {},
   "source": [
    "1. Write the same with statement that we used in the learn section.\n",
    "\n",
    "2. Create a list called futures.\n",
    "\n",
    "3. For each value in the values list, use executor.submit(increment, value) to create a Future object in the futures list.\n",
    "\n",
    "4. Outside of the with statement, create a list with all results from the futures list. Assign it to a variable named results.\n",
    "\n",
    "### Inspect the value of results to see if it contains the expected results: [2, 3, 4, 5, 6, 7, 8, 9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dd19dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'increment' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'increment' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kw/srzmwfqn4sbcw3361mxwtgg80000gn/T/ipykernel_71603/3107890033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kw/srzmwfqn4sbcw3361mxwtgg80000gn/T/ipykernel_71603/3107890033.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def increment(value):\n",
    "    return value + 1\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "# Add code here\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    futures = [executor.submit(increment, value) for value in values]\n",
    "\n",
    "results = [future.result() for future in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b21d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'count_skills' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kw/srzmwfqn4sbcw3361mxwtgg80000gn/T/ipykernel_71603/2112314909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_skills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_postings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_chunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mskill_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskill_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kw/srzmwfqn4sbcw3361mxwtgg80000gn/T/ipykernel_71603/2112314909.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_skills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_postings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_chunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mskill_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskill_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "skill_chunks = make_chunks(skills, 8)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    futures = [executor.submit(count_skills, job_postings, skill_chunk) for skill_chunk in skill_chunks]\n",
    "\n",
    "results = [future.result() for future in futures]\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf935b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
